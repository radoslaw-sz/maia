name: Maia Tests

on: [push]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      # Checkout repo
      - name: Checkout code
        uses: actions/checkout@v4

      # Setup Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      # Install Ollama
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama --version

      # Start Ollama service first
      - name: Start Ollama service
        run: |
          nohup ollama serve > /tmp/ollama.log 2>&1 &
          # Wait for service to be ready
          timeout 30 bash -c 'until curl -s http://localhost:11434/api/tags >/dev/null 2>&1; do sleep 1; done'
          echo "Ollama service is ready"

      # Create ollama directory structure
      - name: Create Ollama directories
        run: |
          mkdir -p $HOME/.ollama

      # Restore Ollama models cache
      - name: Restore Ollama models cache
        uses: actions/cache/restore@v4
        id: ollama-cache
        with:
          path: ~/.ollama
          key: ollama-models-${{ runner.os }}-mistral-v2
          restore-keys: |
            ollama-models-${{ runner.os }}-mistral-
            ollama-models-${{ runner.os }}-
        
      - name: Debug Ollama environment
        run: |
          echo "OLLAMA_MODELS environment: $OLLAMA_MODELS"
          echo "Ollama serve log:"
          tail -n 20 /tmp/ollama.log || echo "No log file yet"

      # Check if model exists and pull if needed
      - name: Pull Mistral model if not cached
        run: |
          # Check if model exists by listing models
          if ollama list | grep -q "mistral"; then
            echo "Mistral model found in cache"
          else
            echo "Mistral model not found, pulling..."
            ollama pull mistral
            echo "Model pulled successfully"
          fi
          
          # Verify model is available
          ollama list

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install -U pip
          python -m pip install -e ./framework
          python -m pip install pytest pytest-asyncio

      # Run tests with Maia plugin
      - name: Run tests
        run: |
          pytest framework/tests/basic/test_content_assertions.py --maia-report results.json
          cat results.json

      # Upload unified test report as artifact
      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: maia-results
          path: results.json

      # Save Ollama models cache
      - name: Save Ollama models cache
        uses: actions/cache/save@v4
        if: steps.ollama-cache.outputs.cache-hit != 'true'
        with:
          path: ~/.ollama/models
          key: ollama-models-${{ runner.os }}-mistral-v3