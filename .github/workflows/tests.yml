name: Maia Tests

on: [push]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      # Checkout repo
      - name: Checkout code
        uses: actions/checkout@v4

      # Setup Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      # Install Ollama
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama --version

      # Restore Ollama models cache
      - name: Restore Ollama models cache
        uses: actions/cache/restore@v4
        id: ollama-cache
        with:
          path: $HOME/.ollama/models
          key: ollama-models-${{ runner.os }}-mistral
          restore-keys: |
            ollama-models-${{ runner.os }}-

      # Debug after restore
      - name: Debug Ollama models path (after restore)
        run: |
          echo "Contents of ~/.ollama after cache restore:"
          ls -R $HOME/.ollama || echo "No ~/.ollama directory found"

      # Pull Mistral model only if cache miss
      - name: Pull Mistral model
        run: |
          if [ ! -d ~/.ollama/models/mistral ]; then
            echo "No cached model found, pulling mistral..."
            ollama pull mistral
          else
            echo "Mistral model already cached."
          fi

      # Debug after pull
      - name: Debug Ollama models path (after pull)
        run: |
          echo "Contents of ~/.ollama after pull:"
          ls -R $HOME/.ollama || echo "No ~/.ollama directory found"

      - name: Locate Ollama models
        run: |
          echo "Looking for mistral model files..."
          for d in "$HOME/.ollama" /usr/share/ollama /var/lib/ollama /usr/local/share/ollama; do
            if [ -d "$d" ]; then
              echo "Checking $d"
              find "$d" -maxdepth 3 -type d -name "mistral" || true
            fi
          done

      # Start Ollama service
      - name: Start Ollama service
        run: |
          nohup ollama serve > /tmp/ollama.log 2>&1 &
          sleep 5

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install -U pip
          python -m pip install -e ./framework
          python -m pip install pytest pytest-asyncio

      # Run tests with Maia plugin
      - name: Run tests
        run: |
          pytest framework/tests/basic/test_content_assertions.py --maia-report results.json
          cat results.json

      # Upload unified test report as artifact
      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: maia-results
          path: results.json

      # Debug before saving cache
      - name: Debug Ollama models path (before save)
        run: |
          echo "Contents of ~/.ollama before cache save:"
          ls -R $HOME/.ollama || echo "No ~/.ollama directory found"

      # Save Ollama models cache after run
      - name: Save Ollama models cache
        uses: actions/cache/save@v4
        if: always()
        with:
          path: $HOME/.ollama/models
          key: ollama-models-${{ runner.os }}-mistral
